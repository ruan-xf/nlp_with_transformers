我来帮你整理这些多标签分类问题，并使用不同的工具计算每类的混淆矩阵。

### 1. 首先整理数据为矩阵形式

```python
import numpy as np
from sklearn.metrics import multilabel_confusion_matrix
import torch

# 真实标签 (6个类别A-F)
y_true = np.array([
    [1,0,1,0,1,0],  # 问题1
    [0,1,0,1,0,0],  # 问题2
    [1,1,0,0,0,1],  # 问题3
    [0,0,1,1,1,0],  # 问题4
    [1,0,0,0,1,1]   # 问题5
])

# 预测标签
y_pred = np.array([
    [1,0,1,0,0,1],  # 问题1
    [0,1,0,1,1,0],  # 问题2
    [1,1,0,0,0,0],  # 问题3
    [0,0,1,0,1,0],  # 问题4
    [1,0,0,1,1,1]   # 问题5
])
```

### 2. 使用NumPy计算每类混淆矩阵

```python
def np_confusion_matrix(y_true, y_pred):
    classes = y_true.shape[1]
    cm = np.zeros((classes, 2, 2), dtype=int)
    
    for i in range(classes):
        tp = np.sum((y_true[:,i] == 1) & (y_pred[:,i] == 1))
        fp = np.sum((y_true[:,i] == 0) & (y_pred[:,i] == 1))
        fn = np.sum((y_true[:,i] == 1) & (y_pred[:,i] == 0))
        tn = np.sum((y_true[:,i] == 0) & (y_pred[:,i] == 0))
        cm[i] = [[tn, fp], [fn, tp]]
    
    return cm

np_cm = np_confusion_matrix(y_true, y_pred)
print("NumPy Confusion Matrices:\n", np_cm)
```

### 3. 使用scikit-learn计算

```python
sk_cm = multilabel_confusion_matrix(y_true, y_pred)
print("\nScikit-learn Confusion Matrices:\n", sk_cm)
```

### 4. 使用PyTorch计算

```python
def torch_confusion_matrix(y_true, y_pred):
    y_true_t = torch.tensor(y_true)
    y_pred_t = torch.tensor(y_pred)
    classes = y_true_t.size(1)
    cm = torch.zeros(classes, 2, 2, dtype=torch.int32)
    
    for i in range(classes):
        tp = torch.sum((y_true_t[:,i] == 1) & (y_pred_t[:,i] == 1)).item()
        fp = torch.sum((y_true_t[:,i] == 0) & (y_pred_t[:,i] == 1)).item()
        fn = torch.sum((y_true_t[:,i] == 1) & (y_pred_t[:,i] == 0)).item()
        tn = torch.sum((y_true_t[:,i] == 0) & (y_pred_t[:,i] == 0)).item()
        cm[i] = torch.tensor([[tn, fp], [fn, tp]])
    
    return cm

torch_cm = torch_confusion_matrix(y_true, y_pred)
print("\nPyTorch Confusion Matrices:\n", torch_cm)
```

### 5. 结果解释

所有三种方法将输出6个混淆矩阵（对应A-F六个类别），每个矩阵形式为：

```
[[TN FP]
 [FN TP]]
```

例如，对于类别A：
- 真正例(TP)：预测为A且实际为A的次数
- 假正例(FP)：预测为A但实际不是A的次数
- 假反例(FN)：实际为A但预测不是A的次数
- 真反例(TN)：实际不是A且预测也不是A的次数

### 6. 完整结果示例

以类别A（第一个类别）为例：

```
类别A混淆矩阵:
[[TN FP]   [[2 0]
 [FN TP]] =  [0 3]]
```

解释：
- TP=3：问题1、3、5中实际有A且预测正确
- FP=0：没有错误预测A的情况
- FN=0：没有漏掉A的情况
- TN=2：问题2、4中实际没有A且预测正确